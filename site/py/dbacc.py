""" Autogenerated db CRUD and related utilities """
########################################
#
#       D O   N O T   E D I T
#
# This file was written by makeCRUD.js.  Any changes should be made there.
#
########################################

#pylint: disable=line-too-long
#pylint: disable=too-many-lines
#pylint: disable=trailing-newlines
#pylint: disable=wrong-import-position
#pylint: disable=wrong-import-order
#pylint: disable=invalid-name
#pylint: disable=missing-function-docstring
#pylint: disable=consider-using-in
#pylint: disable=logging-not-lazy
#pylint: disable=inconsistent-return-statements
#pylint: disable=too-many-return-statements
#pylint: disable=too-many-branches
#pylint: disable=too-many-locals
#pylint: disable=unused-argument
import logging
import flask
import re
import datetime
import pickle
import json
import mysql.connector
import py.mconf as mconf

# Notes:
# (1) In general, all processing that might raise a mysql.connector.Error is
# wrapped to raise a ValueError instead, to support callers working at a
# higher level of CRUD abstraction.  The general processing contruct
#    except mysql.connector.Error as e:
#        raise ValueError from e
# is not used for this purpose because it produces an undecorated ValueError
# without the str(e) text, making it harder to track down what the problem
# actually was.  The source can be found from the Error __context__, but
# that is also set when raising a new Error, so the general use here is
#        raise ValueError(str(e) or "No mysql error text")

# Reserved database fields used for every instance:
#  - dsId: a long int, possibly out of range of a javascript integer,
#    possibly non-sequential, uniquely identifying an entity instance.
#    The entity type + dsId uniquely identifies an object in the system.
#  - created: An ISO timestamp when the instance was first written.
#  - modified: An ISO timestamp followed by ';' followed by mod count.
#  - batchconv: Arbitray string for batch database conversion.
dbflds = {"dsId": {"pt": "dbid", "un": True, "dv": 0},
          "created": {"pt": "string", "un": False, "dv": ""},
          "modified": {"pt": "string", "un": False, "dv": ""},
          "batchconv": {"pt": "string", "un": False, "dv": ""}}

entdefs = {
    "DigAcc": {  # Digger Hub access account
        "dsId": {"pt": "dbid", "un": True, "dv": 0},
        "created": {"pt": "string", "un": False, "dv": ""},
        "modified": {"pt": "string", "un": False, "dv": ""},
        "batchconv": {"pt": "string", "un": False, "dv": ""},
        "email": {"pt": "email", "un": True, "dv": ""},
        "phash": {"pt": "string", "un": False, "dv": ""},
        "hubdat": {"pt": "string", "un": False, "dv": ""},
        "status": {"pt": "string", "un": False, "dv": ""},
        "actsends": {"pt": "string", "un": False, "dv": ""},
        "actcode": {"pt": "string", "un": False, "dv": ""},
        "firstname": {"pt": "string", "un": False, "dv": ""},
        "hashtag": {"pt": "string", "un": True, "dv": ""},
        "kwdefs": {"pt": "string", "un": False, "dv": ""},
        "igfolds": {"pt": "string", "un": False, "dv": ""},
        "settings": {"pt": "string", "un": False, "dv": ""},
        "musfs": {"pt": "string", "un": False, "dv": ""}
    },
    "Song": {  # Rating and play information
        "dsId": {"pt": "dbid", "un": True, "dv": 0},
        "created": {"pt": "string", "un": False, "dv": ""},
        "modified": {"pt": "string", "un": False, "dv": ""},
        "batchconv": {"pt": "string", "un": False, "dv": ""},
        "aid": {"pt": "dbid", "un": False, "dv": 0},
        "path": {"pt": "string", "un": False, "dv": ""},
        "ti": {"pt": "string", "un": False, "dv": ""},
        "ar": {"pt": "string", "un": False, "dv": ""},
        "ab": {"pt": "string", "un": False, "dv": ""},
        "smti": {"pt": "string", "un": False, "dv": ""},
        "smar": {"pt": "string", "un": False, "dv": ""},
        "smab": {"pt": "string", "un": False, "dv": ""},
        "el": {"pt": "int", "un": False, "dv": 0},
        "al": {"pt": "int", "un": False, "dv": 0},
        "kws": {"pt": "string", "un": False, "dv": ""},
        "rv": {"pt": "int", "un": False, "dv": 0},
        "fq": {"pt": "string", "un": False, "dv": ""},
        "lp": {"pt": "string", "un": False, "dv": ""},
        "nt": {"pt": "string", "un": False, "dv": ""},
        "pc": {"pt": "int", "un": False, "dv": 0},
        "srcid": {"pt": "dbid", "un": False, "dv": 0},
        "srcrat": {"pt": "string", "un": False, "dv": ""},
        "spid": {"pt": "string", "un": False, "dv": ""}
    },
    "Collab": {  # Initial ratings, suggestions and such
        "dsId": {"pt": "dbid", "un": True, "dv": 0},
        "created": {"pt": "string", "un": False, "dv": ""},
        "modified": {"pt": "string", "un": False, "dv": ""},
        "batchconv": {"pt": "string", "un": False, "dv": ""},
        "ctype": {"pt": "string", "un": False, "dv": ""},
        "rec": {"pt": "dbid", "un": False, "dv": 0},
        "src": {"pt": "dbid", "un": False, "dv": 0},
        "ssid": {"pt": "dbid", "un": False, "dv": 0}
    },
    "SKeyMap": {  # Song Title/Artist/Album key mappings
        "dsId": {"pt": "dbid", "un": True, "dv": 0},
        "created": {"pt": "string", "un": False, "dv": ""},
        "modified": {"pt": "string", "un": False, "dv": ""},
        "batchconv": {"pt": "string", "un": False, "dv": ""},
        "skey": {"pt": "string", "un": True, "dv": ""},
        "spid": {"pt": "string", "un": False, "dv": ""},
        "notes": {"pt": "string", "un": False, "dv": ""}
    },
    "AppService": {  # Processing service access
        "dsId": {"pt": "dbid", "un": True, "dv": 0},
        "created": {"pt": "string", "un": False, "dv": ""},
        "modified": {"pt": "string", "un": False, "dv": ""},
        "batchconv": {"pt": "string", "un": False, "dv": ""},
        "name": {"pt": "string", "un": True, "dv": ""},
        "ckey": {"pt": "string", "un": False, "dv": ""},
        "csec": {"pt": "string", "un": False, "dv": ""},
        "data": {"pt": "string", "un": False, "dv": ""}
    }
}


entkeys = {
    "DigAcc": ["email", "hashtag"],
    "Song": [],
    "Collab": [],
    "SKeyMap": ["skey"],
    "AppService": ["name"]
}


cachedefs = {
    "DigAcc": {"minutes": 120, "manualadd": False},
    "Song": {"minutes": 0, "manualadd": False},
    "Collab": {"minutes": 0, "manualadd": False},
    "SKeyMap": {"minutes": 0, "manualadd": False},
    "AppService": {"minutes": 240, "manualadd": False}
}


def timestamp(offset=0):
    now = datetime.datetime.utcnow().replace(microsecond=0)
    return dt2ISO(now + datetime.timedelta(minutes=offset))


def expiration_for_inst(inst):
    if not inst or not inst["dsId"]:
        raise ValueError("Uncacheable instance: " + str(inst))
    cms = cachedefs[inst["dsType"]]
    if not cms or not cms["minutes"]:
        return ""  # not cached, no time to live
    return timestamp(cms["minutes"])


def make_key(dsType, field, value):
    # The value param will always be a string because after retrieving an
    # instance via query, the resulting fields are converted via db2app.
    return dsType + "_" + field + "_" + value


def entkey_vals(inst):
    # dsId key holds the cached instance.  Need img data so pickle.
    instkey = make_key(inst["dsType"], "dsId", inst["dsId"])
    keyvals = [{"key": instkey, "val": pickle.dumps(inst)}]
    # alternate entity keys point to the dsId key
    for field in entkeys[inst["dsType"]]:
        keyvals.append({"key": make_key(inst["dsType"], field, inst[field]),
                        "val": instkey})
    return keyvals


# Avoids repeated calls to the db for the same instance, especially within
# the same call to the webserver.  Used sparingly to avoid chewing memory.
# Time to live can range from zero to whenever in actual runtime use.
class EntityCache():
    """ Special case runtime cache to avoid pounding the db repeatedly """
    entities = {}
    def cache_put(self, inst):
        expir = expiration_for_inst(inst)
        if expir:  # cacheable
            self.cache_remove(inst)  # clear any outdated entries
            kt = inst["dsType"] + "_" + inst["dsId"] + "_cleanup"
            cachekeys = ["TTL_" + expir]
            for keyval in entkey_vals(inst):
                cachekeys.append(keyval["key"])
                self.entities[keyval["key"]] = keyval["val"]
            self.entities[kt] = ",".join(cachekeys)
            # self.log_cache_entries()
    def cache_get(self, entity, field, value):
        instkey = make_key(entity, field, value)
        if instkey not in self.entities:
            return None
        instval = self.entities[instkey]
        if field != "dsId":
            instval = self.entities[instval]
        return pickle.loads(instval)
    def cache_remove(self, inst):
        if inst:
            kt = inst["dsType"] + "_" + inst["dsId"] + "_cleanup"
            cleankeys = self.entities.pop(kt, None)
            if cleankeys:
                for oldkey in cleankeys.split(","):
                    self.entities.pop(oldkey, None)
    def cache_clean(self):
        now = nowISO()
        for key, value in self.entities.items():
            if key.endswith("_cleanup"):
                ttl = value.split(",")[0][4:]
                if ttl < now:
                    kcs = key.split("_")
                    inst = {"dsType": kcs[0], "dsId": kcs[1]}
                    self.cache_remove(inst)
    def log_cache_entries(self):
        txt = "EntityCache entities:\n"
        for key, _ in self.entities.items():
            txt += "    " + key + ": " + str(self.entities[key])[0:74] + "\n"
        logging.info(txt)
        return txt
entcache = EntityCache()


def reqarg(argname, fieldtype="string", required=False):
    argval = flask.request.args.get(argname)  # None if not found
    if not argval:
        argval = flask.request.form.get(argname)  # Ditto
    if required and not argval:
        raise ValueError("Missing required value for " + argname)
    dotidx = fieldtype.find('.')
    if dotidx > 0:
        entity = fieldtype[0:dotidx]
        fieldname = fieldtype[dotidx + 1:]
        fieldtype = entdefs[entity][fieldname]["pt"]
    if fieldtype == "email":
        emaddr = argval or ""
        emaddr = emaddr.lower()
        emaddr = re.sub('%40', '@', emaddr)
        if required and not re.match(r"[^@]+@[^@]+\.[^@]+", emaddr):
            raise ValueError("Invalid " + argname + " value: " + emaddr)
        return emaddr
    # A dbid is an int in the db and a string everywhere else
    if fieldtype in ["dbid", "string", "isodate", "isomod", "srchidcsv", "text",
                     "json", "jsarr", "idcsv", "isodcsv", "gencsv", "url"]:
        return argval or ""
    if fieldtype == "image":
        return argval or None
    if fieldtype == "int":
        argval = argval or 0
        return int(argval)
    raise ValueError("Unknown type " + fieldtype + " for " + argname)


# "cached fetch by key". Field must be dsId or one of the entkeys.
def cfbk(entity, field, value, required=False):
    if field != 'dsId' and field not in entkeys[entity]:
        raise ValueError(field + " not a unique index for " + entity)
    vstr = str(value)
    ci = entcache.cache_get(entity, field, vstr)
    if ci:
        dblogmsg("CAC", entity, ci)
        return ci
    if entdefs[entity][field]["pt"] not in ["dbid", "int"]:
        vstr = "\"" + vstr + "\""
    objs = query_entity(entity, "WHERE " + field + "=" + vstr + " LIMIT 1")
    if len(objs) > 0:
        inst = objs[0]
        if not cachedefs[inst["dsType"]]["manualadd"]:
            entcache.cache_put(inst)
        return inst
    if required:
        raise ValueError(entity + " " + vstr + " not found.")
    return None


# Get a connection to the database.  May throw mysql.connector.Error
# https://dev.mysql.com/doc/connector-python/en/connector-python-connectargs.html
def get_mysql_connector():
    cnx = None
    try:
        cnx = mysql.connector.connect(user=mconf.db["u"],
                                      password=mconf.db["p"],
                                      host=mconf.db["h"],
                                      database=mconf.db["d"])
    except Exception as e:
        raise ValueError("Connection failed: " + str(e))
    return cnx


# Given what should be a string value, remove preceding or trailing space.
# If unique is true, then treat values of "null" or "None" as "".
def trim_string_val(val, unique=False):
    val = val or ""
    val = str(val)
    val = val.strip()
    if val and unique:
        lowval = val.lower()
        if lowval in ["null", "none"]:
            val = ""
    return val


# Read the given field from the inst or the default values, then convert it
# from an app value to a db value.  All string values are trimmed since
# preceding or trailing space makes matching horrible and buggy.  The UI can
# add a trailing newline for long text if it wants.
def app2db_fieldval(entity, field, inst):
    if entity:
        pt = entdefs[entity][field]["pt"]
        unique = entdefs[entity][field]["un"]
        val = entdefs[entity][field]["dv"]
    else:
        pt = dbflds[field]["pt"]
        unique = dbflds[field]["un"]
        val = dbflds[field]["dv"]
    if field in inst:
        val = inst[field]
    # convert value based on type and whether the values are unique
    if pt in ["email", "string"]:
        val = val or ""
        val = trim_string_val(val, unique)  # trim all strings. See comment.
        if not val:
            val = None
    elif pt == "image":
        if not val:  # Empty data gets set to null
            val = None
    elif pt == "int":
        val = val or 0
        val = int(val)  # convert possible "0" value
    elif pt == "dbid":
        try:
            val = int(val)  # will fail on "", "null" or other bad values
        except ValueError:
            val = 0
        if unique and not val:  # null vals don't violate UNIQUE constraint
            val = None          # otherwise use 0 as val may be required
    return val


# Read the given field from the inst or the default values, then convert it
# from a db value to an app value.  "app" means the server side module
# calling this module, not the web client.  Image binary values and json
# field values are not decoded, but get safe defaults if NULL.  dbids are
# converted to strings.
def db2app_fieldval(entity, field, inst):
    if entity:
        pt = entdefs[entity][field]["pt"]
        val = entdefs[entity][field]["dv"]
    else:
        pt = dbflds[field]["pt"]
        val = dbflds[field]["dv"]
    if field in inst:
        val = inst[field]
    # convert value based on type
    if pt in ["email", "string"]:
        if not val:  # A null value gets set to the empty string
            val = ""
        val = str(val)  # db interface might have autoconverted to int
    elif pt == "image":
        if not val:  # A null value gets set to the empty string
            val = ""
    elif pt == "int":
        if not val:  # Convert null values to 0
            val = 0
    elif pt == "dbid":
        if not val:  # A zero or null value gets set to falsey empty string
            val = ""
        else:
            val = str(val)
    return val


def ISO2dt(isostr):
    isostr = re.sub(r"\.\d*Z", "Z", isostr)  # remove microsecond if any
    dt = datetime.datetime.utcnow()
    dt = dt.strptime(isostr, "%Y-%m-%dT%H:%M:%SZ")
    return dt


def dt2ISO(dt):
    iso = str(dt.year) + "-" + str(dt.month).rjust(2, '0') + "-"
    iso += str(dt.day).rjust(2, '0') + "T" + str(dt.hour).rjust(2, '0')
    iso += ":" + str(dt.minute).rjust(2, '0') + ":"
    iso += str(dt.second).rjust(2, '0') + "Z"
    return iso


def nowISO():
    """ Return the current time as an ISO string """
    return dt2ISO(datetime.datetime.utcnow())


def initialize_timestamp_fields(fields, vck):
    ts = nowISO()
    if "created" not in fields or not fields["created"] or vck != "override":
        fields["created"] = ts
    if "modified" not in fields or not fields["modified"] or vck != "override":
        fields["modified"] = ts + ";1"


def verify_timestamp_fields(entity, dsId, fields, vck):
    if vck == "override" and "created" in fields and "modified" in fields:
        return fields # skip query and use specified values
    if not vck or not vck.strip():
        raise ValueError("Version check required to update " + entity +
                         " " + str(dsId))
    existing = cfbk(entity, "dsId", dsId)
    if not existing:
        raise ValueError("Existing " + entity + " " + str(dsId) + " not found.")
    if vck != "override" and existing["modified"] != vck:
        logging.error("verify_timestamp_fields rejecting mod of " + entity +
                      " " + str(dsId) + ". existing: " + existing["modified"] +
                      ", received: " + vck + ".")
        raise ValueError("Update error. Outdated data given for " + entity +
                         " " + str(dsId) + ".")
    if "created" not in fields or not fields["created"] or vck != "override":
        fields["created"] = existing["created"]
    ver = 1
    mods = existing["modified"].split(";")
    if len(mods) > 1:
        ver = int(mods[1]) + 1
    if "modified" not in fields or not fields["modified"] or vck != "override":
        fields["modified"] = nowISO() + ";" + str(ver)
    return existing


# Convert the given DigAcc inst dict from app values to db values.  Removes
# the dsType field to avoid trying to write it to the db.
def app2db_DigAcc(inst, fill=True):
    cnv = {}
    cnv["dsId"] = None
    if "dsId" in inst:
        cnv["dsId"] = app2db_fieldval(None, "dsId", inst)
    if fill or "created" in inst:
        cnv["created"] = app2db_fieldval(None, "created", inst)
    if fill or "modified" in inst:
        cnv["modified"] = app2db_fieldval(None, "modified", inst)
    if fill or "batchconv" in inst:
        cnv["batchconv"] = app2db_fieldval(None, "batchconv", inst)
    if fill or "email" in inst:
        cnv["email"] = app2db_fieldval("DigAcc", "email", inst)
    if fill or "phash" in inst:
        cnv["phash"] = app2db_fieldval("DigAcc", "phash", inst)
    if fill or "hubdat" in inst:
        cnv["hubdat"] = app2db_fieldval("DigAcc", "hubdat", inst)
    if fill or "status" in inst:
        cnv["status"] = app2db_fieldval("DigAcc", "status", inst)
    if fill or "actsends" in inst:
        cnv["actsends"] = app2db_fieldval("DigAcc", "actsends", inst)
    if fill or "actcode" in inst:
        cnv["actcode"] = app2db_fieldval("DigAcc", "actcode", inst)
    if fill or "firstname" in inst:
        cnv["firstname"] = app2db_fieldval("DigAcc", "firstname", inst)
    if fill or "hashtag" in inst:
        cnv["hashtag"] = app2db_fieldval("DigAcc", "hashtag", inst)
    if fill or "kwdefs" in inst:
        cnv["kwdefs"] = app2db_fieldval("DigAcc", "kwdefs", inst)
    if fill or "igfolds" in inst:
        cnv["igfolds"] = app2db_fieldval("DigAcc", "igfolds", inst)
    if fill or "settings" in inst:
        cnv["settings"] = app2db_fieldval("DigAcc", "settings", inst)
    if fill or "musfs" in inst:
        cnv["musfs"] = app2db_fieldval("DigAcc", "musfs", inst)
    return cnv


# Convert the given DigAcc inst dict from db values to app values.  Adds the
# dsType field for general app processing.
def db2app_DigAcc(inst):
    cnv = {}
    cnv["dsType"] = "DigAcc"
    cnv["dsId"] = db2app_fieldval(None, "dsId", inst)
    cnv["created"] = db2app_fieldval(None, "created", inst)
    cnv["modified"] = db2app_fieldval(None, "modified", inst)
    cnv["batchconv"] = db2app_fieldval(None, "batchconv", inst)
    cnv["email"] = db2app_fieldval("DigAcc", "email", inst)
    cnv["phash"] = db2app_fieldval("DigAcc", "phash", inst)
    cnv["hubdat"] = db2app_fieldval("DigAcc", "hubdat", inst)
    cnv["status"] = db2app_fieldval("DigAcc", "status", inst)
    cnv["actsends"] = db2app_fieldval("DigAcc", "actsends", inst)
    cnv["actcode"] = db2app_fieldval("DigAcc", "actcode", inst)
    cnv["firstname"] = db2app_fieldval("DigAcc", "firstname", inst)
    cnv["hashtag"] = db2app_fieldval("DigAcc", "hashtag", inst)
    cnv["kwdefs"] = db2app_fieldval("DigAcc", "kwdefs", inst)
    cnv["igfolds"] = db2app_fieldval("DigAcc", "igfolds", inst)
    cnv["settings"] = db2app_fieldval("DigAcc", "settings", inst)
    cnv["musfs"] = db2app_fieldval("DigAcc", "musfs", inst)
    return cnv


# Convert the given Song inst dict from app values to db values.  Removes
# the dsType field to avoid trying to write it to the db.
def app2db_Song(inst, fill=True):
    cnv = {}
    cnv["dsId"] = None
    if "dsId" in inst:
        cnv["dsId"] = app2db_fieldval(None, "dsId", inst)
    if fill or "created" in inst:
        cnv["created"] = app2db_fieldval(None, "created", inst)
    if fill or "modified" in inst:
        cnv["modified"] = app2db_fieldval(None, "modified", inst)
    if fill or "batchconv" in inst:
        cnv["batchconv"] = app2db_fieldval(None, "batchconv", inst)
    if fill or "aid" in inst:
        cnv["aid"] = app2db_fieldval("Song", "aid", inst)
    if fill or "path" in inst:
        cnv["path"] = app2db_fieldval("Song", "path", inst)
    if fill or "ti" in inst:
        cnv["ti"] = app2db_fieldval("Song", "ti", inst)
    if fill or "ar" in inst:
        cnv["ar"] = app2db_fieldval("Song", "ar", inst)
    if fill or "ab" in inst:
        cnv["ab"] = app2db_fieldval("Song", "ab", inst)
    if fill or "smti" in inst:
        cnv["smti"] = app2db_fieldval("Song", "smti", inst)
    if fill or "smar" in inst:
        cnv["smar"] = app2db_fieldval("Song", "smar", inst)
    if fill or "smab" in inst:
        cnv["smab"] = app2db_fieldval("Song", "smab", inst)
    if fill or "el" in inst:
        cnv["el"] = app2db_fieldval("Song", "el", inst)
    if fill or "al" in inst:
        cnv["al"] = app2db_fieldval("Song", "al", inst)
    if fill or "kws" in inst:
        cnv["kws"] = app2db_fieldval("Song", "kws", inst)
    if fill or "rv" in inst:
        cnv["rv"] = app2db_fieldval("Song", "rv", inst)
    if fill or "fq" in inst:
        cnv["fq"] = app2db_fieldval("Song", "fq", inst)
    if fill or "lp" in inst:
        cnv["lp"] = app2db_fieldval("Song", "lp", inst)
    if fill or "nt" in inst:
        cnv["nt"] = app2db_fieldval("Song", "nt", inst)
    if fill or "pc" in inst:
        cnv["pc"] = app2db_fieldval("Song", "pc", inst)
    if fill or "srcid" in inst:
        cnv["srcid"] = app2db_fieldval("Song", "srcid", inst)
    if fill or "srcrat" in inst:
        cnv["srcrat"] = app2db_fieldval("Song", "srcrat", inst)
    if fill or "spid" in inst:
        cnv["spid"] = app2db_fieldval("Song", "spid", inst)
    return cnv


# Convert the given Song inst dict from db values to app values.  Adds the
# dsType field for general app processing.
def db2app_Song(inst):
    cnv = {}
    cnv["dsType"] = "Song"
    cnv["dsId"] = db2app_fieldval(None, "dsId", inst)
    cnv["created"] = db2app_fieldval(None, "created", inst)
    cnv["modified"] = db2app_fieldval(None, "modified", inst)
    cnv["batchconv"] = db2app_fieldval(None, "batchconv", inst)
    cnv["aid"] = db2app_fieldval("Song", "aid", inst)
    cnv["path"] = db2app_fieldval("Song", "path", inst)
    cnv["ti"] = db2app_fieldval("Song", "ti", inst)
    cnv["ar"] = db2app_fieldval("Song", "ar", inst)
    cnv["ab"] = db2app_fieldval("Song", "ab", inst)
    cnv["smti"] = db2app_fieldval("Song", "smti", inst)
    cnv["smar"] = db2app_fieldval("Song", "smar", inst)
    cnv["smab"] = db2app_fieldval("Song", "smab", inst)
    cnv["el"] = db2app_fieldval("Song", "el", inst)
    cnv["al"] = db2app_fieldval("Song", "al", inst)
    cnv["kws"] = db2app_fieldval("Song", "kws", inst)
    cnv["rv"] = db2app_fieldval("Song", "rv", inst)
    cnv["fq"] = db2app_fieldval("Song", "fq", inst)
    cnv["lp"] = db2app_fieldval("Song", "lp", inst)
    cnv["nt"] = db2app_fieldval("Song", "nt", inst)
    cnv["pc"] = db2app_fieldval("Song", "pc", inst)
    cnv["srcid"] = db2app_fieldval("Song", "srcid", inst)
    cnv["srcrat"] = db2app_fieldval("Song", "srcrat", inst)
    cnv["spid"] = db2app_fieldval("Song", "spid", inst)
    return cnv


# Convert the given Collab inst dict from app values to db values.  Removes
# the dsType field to avoid trying to write it to the db.
def app2db_Collab(inst, fill=True):
    cnv = {}
    cnv["dsId"] = None
    if "dsId" in inst:
        cnv["dsId"] = app2db_fieldval(None, "dsId", inst)
    if fill or "created" in inst:
        cnv["created"] = app2db_fieldval(None, "created", inst)
    if fill or "modified" in inst:
        cnv["modified"] = app2db_fieldval(None, "modified", inst)
    if fill or "batchconv" in inst:
        cnv["batchconv"] = app2db_fieldval(None, "batchconv", inst)
    if fill or "ctype" in inst:
        cnv["ctype"] = app2db_fieldval("Collab", "ctype", inst)
    if fill or "rec" in inst:
        cnv["rec"] = app2db_fieldval("Collab", "rec", inst)
    if fill or "src" in inst:
        cnv["src"] = app2db_fieldval("Collab", "src", inst)
    if fill or "ssid" in inst:
        cnv["ssid"] = app2db_fieldval("Collab", "ssid", inst)
    return cnv


# Convert the given Collab inst dict from db values to app values.  Adds the
# dsType field for general app processing.
def db2app_Collab(inst):
    cnv = {}
    cnv["dsType"] = "Collab"
    cnv["dsId"] = db2app_fieldval(None, "dsId", inst)
    cnv["created"] = db2app_fieldval(None, "created", inst)
    cnv["modified"] = db2app_fieldval(None, "modified", inst)
    cnv["batchconv"] = db2app_fieldval(None, "batchconv", inst)
    cnv["ctype"] = db2app_fieldval("Collab", "ctype", inst)
    cnv["rec"] = db2app_fieldval("Collab", "rec", inst)
    cnv["src"] = db2app_fieldval("Collab", "src", inst)
    cnv["ssid"] = db2app_fieldval("Collab", "ssid", inst)
    return cnv


# Convert the given SKeyMap inst dict from app values to db values.  Removes
# the dsType field to avoid trying to write it to the db.
def app2db_SKeyMap(inst, fill=True):
    cnv = {}
    cnv["dsId"] = None
    if "dsId" in inst:
        cnv["dsId"] = app2db_fieldval(None, "dsId", inst)
    if fill or "created" in inst:
        cnv["created"] = app2db_fieldval(None, "created", inst)
    if fill or "modified" in inst:
        cnv["modified"] = app2db_fieldval(None, "modified", inst)
    if fill or "batchconv" in inst:
        cnv["batchconv"] = app2db_fieldval(None, "batchconv", inst)
    if fill or "skey" in inst:
        cnv["skey"] = app2db_fieldval("SKeyMap", "skey", inst)
    if fill or "spid" in inst:
        cnv["spid"] = app2db_fieldval("SKeyMap", "spid", inst)
    if fill or "notes" in inst:
        cnv["notes"] = app2db_fieldval("SKeyMap", "notes", inst)
    return cnv


# Convert the given SKeyMap inst dict from db values to app values.  Adds the
# dsType field for general app processing.
def db2app_SKeyMap(inst):
    cnv = {}
    cnv["dsType"] = "SKeyMap"
    cnv["dsId"] = db2app_fieldval(None, "dsId", inst)
    cnv["created"] = db2app_fieldval(None, "created", inst)
    cnv["modified"] = db2app_fieldval(None, "modified", inst)
    cnv["batchconv"] = db2app_fieldval(None, "batchconv", inst)
    cnv["skey"] = db2app_fieldval("SKeyMap", "skey", inst)
    cnv["spid"] = db2app_fieldval("SKeyMap", "spid", inst)
    cnv["notes"] = db2app_fieldval("SKeyMap", "notes", inst)
    return cnv


# Convert the given AppService inst dict from app values to db values.  Removes
# the dsType field to avoid trying to write it to the db.
def app2db_AppService(inst, fill=True):
    cnv = {}
    cnv["dsId"] = None
    if "dsId" in inst:
        cnv["dsId"] = app2db_fieldval(None, "dsId", inst)
    if fill or "created" in inst:
        cnv["created"] = app2db_fieldval(None, "created", inst)
    if fill or "modified" in inst:
        cnv["modified"] = app2db_fieldval(None, "modified", inst)
    if fill or "batchconv" in inst:
        cnv["batchconv"] = app2db_fieldval(None, "batchconv", inst)
    if fill or "name" in inst:
        cnv["name"] = app2db_fieldval("AppService", "name", inst)
    if fill or "ckey" in inst:
        cnv["ckey"] = app2db_fieldval("AppService", "ckey", inst)
    if fill or "csec" in inst:
        cnv["csec"] = app2db_fieldval("AppService", "csec", inst)
    if fill or "data" in inst:
        cnv["data"] = app2db_fieldval("AppService", "data", inst)
    return cnv


# Convert the given AppService inst dict from db values to app values.  Adds the
# dsType field for general app processing.
def db2app_AppService(inst):
    cnv = {}
    cnv["dsType"] = "AppService"
    cnv["dsId"] = db2app_fieldval(None, "dsId", inst)
    cnv["created"] = db2app_fieldval(None, "created", inst)
    cnv["modified"] = db2app_fieldval(None, "modified", inst)
    cnv["batchconv"] = db2app_fieldval(None, "batchconv", inst)
    cnv["name"] = db2app_fieldval("AppService", "name", inst)
    cnv["ckey"] = db2app_fieldval("AppService", "ckey", inst)
    cnv["csec"] = db2app_fieldval("AppService", "csec", inst)
    cnv["data"] = db2app_fieldval("AppService", "data", inst)
    return cnv


def dblogmsg(op, entity, res):
    log_summary_flds = {
        "DigAcc": ["email", "firstname"],
        "Song": ["aid", "ti", "ar"],
        "Collab": ["ctype", "rec", "src", "ssid"],
        "SKeyMap": ["skey", "spid"],
        "AppService": ["name"]}
    if res:
        if op != "QRY":  # query is already a list, listify anything else
            res = [res]
        for obj in res:
            msg = "db" + op + " " + entity + " " + obj["dsId"]
            if op in ["UPD", "CAC"]:
                msg += " ;" + obj["modified"].split(";")[1]
            if entity in log_summary_flds:
                for field in log_summary_flds[entity]:
                    msg += " " + str(obj[field])[0:60]
            logging.info(msg)
    else:  # no res, probably a delete
        logging.info("db" + op + " " + entity + " -no obj details-")


# Write a new DigAcc row, using the given field values or defaults.
def insert_new_DigAcc(cnx, cursor, fields):
    fields = app2db_DigAcc(fields)
    stmt = (
        "INSERT INTO DigAcc (created, modified, email, phash, hubdat, status, actsends, actcode, firstname, hashtag, kwdefs, igfolds, settings, musfs) "
        "VALUES (%(created)s, %(modified)s, %(email)s, %(phash)s, %(hubdat)s, %(status)s, %(actsends)s, %(actcode)s, %(firstname)s, %(hashtag)s, %(kwdefs)s, %(igfolds)s, %(settings)s, %(musfs)s)")
    data = {
        'created': fields.get("created"),
        'modified': fields.get("modified"),
        'email': fields.get("email", entdefs["DigAcc"]["email"]["dv"]),
        'phash': fields.get("phash", entdefs["DigAcc"]["phash"]["dv"]),
        'hubdat': fields.get("hubdat", entdefs["DigAcc"]["hubdat"]["dv"]),
        'status': fields.get("status", entdefs["DigAcc"]["status"]["dv"]),
        'actsends': fields.get("actsends", entdefs["DigAcc"]["actsends"]["dv"]),
        'actcode': fields.get("actcode", entdefs["DigAcc"]["actcode"]["dv"]),
        'firstname': fields.get("firstname", entdefs["DigAcc"]["firstname"]["dv"]),
        'hashtag': fields.get("hashtag", entdefs["DigAcc"]["hashtag"]["dv"]),
        'kwdefs': fields.get("kwdefs", entdefs["DigAcc"]["kwdefs"]["dv"]),
        'igfolds': fields.get("igfolds", entdefs["DigAcc"]["igfolds"]["dv"]),
        'settings': fields.get("settings", entdefs["DigAcc"]["settings"]["dv"]),
        'musfs': fields.get("musfs", entdefs["DigAcc"]["musfs"]["dv"])}
    cursor.execute(stmt, data)
    fields["dsId"] = cursor.lastrowid
    cnx.commit()
    fields = db2app_DigAcc(fields)
    dblogmsg("ADD", "DigAcc", fields)
    return fields


# Update the specified DigAcc row with the given field values.
def update_existing_DigAcc(context, fields):
    fields = app2db_DigAcc(fields, fill=False)
    dsId = int(fields["dsId"])  # Verify int value
    stmt = ""
    for field in fields:  # only updating the fields passed in
        if stmt:
            stmt += ", "
        stmt += field + "=(%(" + field + ")s)"
    stmt = "UPDATE DigAcc SET " + stmt + " WHERE dsId=" + str(dsId)
    if context["vck"] != "override":
        stmt += " AND modified=\"" + context["vck"] + "\""
    data = {}
    for field in fields:
        data[field] = fields[field]
    context["cursor"].execute(stmt, data)
    if context["cursor"].rowcount < 1 and context["vck"] != "override":
        logging.error(stmt + " " + json.dumps(data))
        entcache.cache_clean()  # out of sync, clear it all
        raise ValueError("DigAcc" + str(dsId) + " update received outdated version check value " + context["vck"] + ".")
    context["cnx"].commit()
    result = context["existing"]
    for field in fields:
        result[field] = fields[field]
    result = db2app_DigAcc(result)
    dblogmsg("UPD", "DigAcc", result)
    entcache.cache_put(result)
    return result


# Write a new Song row, using the given field values or defaults.
def insert_new_Song(cnx, cursor, fields):
    fields = app2db_Song(fields)
    stmt = (
        "INSERT INTO Song (created, modified, aid, path, ti, ar, ab, smti, smar, smab, el, al, kws, rv, fq, lp, nt, pc, srcid, srcrat, spid) "
        "VALUES (%(created)s, %(modified)s, %(aid)s, %(path)s, %(ti)s, %(ar)s, %(ab)s, %(smti)s, %(smar)s, %(smab)s, %(el)s, %(al)s, %(kws)s, %(rv)s, %(fq)s, %(lp)s, %(nt)s, %(pc)s, %(srcid)s, %(srcrat)s, %(spid)s)")
    data = {
        'created': fields.get("created"),
        'modified': fields.get("modified"),
        'aid': fields.get("aid", entdefs["Song"]["aid"]["dv"]),
        'path': fields.get("path", entdefs["Song"]["path"]["dv"]),
        'ti': fields.get("ti", entdefs["Song"]["ti"]["dv"]),
        'ar': fields.get("ar", entdefs["Song"]["ar"]["dv"]),
        'ab': fields.get("ab", entdefs["Song"]["ab"]["dv"]),
        'smti': fields.get("smti", entdefs["Song"]["smti"]["dv"]),
        'smar': fields.get("smar", entdefs["Song"]["smar"]["dv"]),
        'smab': fields.get("smab", entdefs["Song"]["smab"]["dv"]),
        'el': fields.get("el", entdefs["Song"]["el"]["dv"]),
        'al': fields.get("al", entdefs["Song"]["al"]["dv"]),
        'kws': fields.get("kws", entdefs["Song"]["kws"]["dv"]),
        'rv': fields.get("rv", entdefs["Song"]["rv"]["dv"]),
        'fq': fields.get("fq", entdefs["Song"]["fq"]["dv"]),
        'lp': fields.get("lp", entdefs["Song"]["lp"]["dv"]),
        'nt': fields.get("nt", entdefs["Song"]["nt"]["dv"]),
        'pc': fields.get("pc", entdefs["Song"]["pc"]["dv"]),
        'srcid': fields.get("srcid", entdefs["Song"]["srcid"]["dv"]),
        'srcrat': fields.get("srcrat", entdefs["Song"]["srcrat"]["dv"]),
        'spid': fields.get("spid", entdefs["Song"]["spid"]["dv"])}
    cursor.execute(stmt, data)
    fields["dsId"] = cursor.lastrowid
    cnx.commit()
    fields = db2app_Song(fields)
    dblogmsg("ADD", "Song", fields)
    return fields


# Update the specified Song row with the given field values.
def update_existing_Song(context, fields):
    fields = app2db_Song(fields, fill=False)
    dsId = int(fields["dsId"])  # Verify int value
    stmt = ""
    for field in fields:  # only updating the fields passed in
        if stmt:
            stmt += ", "
        stmt += field + "=(%(" + field + ")s)"
    stmt = "UPDATE Song SET " + stmt + " WHERE dsId=" + str(dsId)
    if context["vck"] != "override":
        stmt += " AND modified=\"" + context["vck"] + "\""
    data = {}
    for field in fields:
        data[field] = fields[field]
    context["cursor"].execute(stmt, data)
    if context["cursor"].rowcount < 1 and context["vck"] != "override":
        logging.error(stmt + " " + json.dumps(data))
        entcache.cache_clean()  # out of sync, clear it all
        raise ValueError("Song" + str(dsId) + " update received outdated version check value " + context["vck"] + ".")
    context["cnx"].commit()
    result = context["existing"]
    for field in fields:
        result[field] = fields[field]
    result = db2app_Song(result)
    dblogmsg("UPD", "Song", result)
    entcache.cache_remove(result)
    return result


# Write a new Collab row, using the given field values or defaults.
def insert_new_Collab(cnx, cursor, fields):
    fields = app2db_Collab(fields)
    stmt = (
        "INSERT INTO Collab (created, modified, ctype, rec, src, ssid) "
        "VALUES (%(created)s, %(modified)s, %(ctype)s, %(rec)s, %(src)s, %(ssid)s)")
    data = {
        'created': fields.get("created"),
        'modified': fields.get("modified"),
        'ctype': fields.get("ctype", entdefs["Collab"]["ctype"]["dv"]),
        'rec': fields.get("rec", entdefs["Collab"]["rec"]["dv"]),
        'src': fields.get("src", entdefs["Collab"]["src"]["dv"]),
        'ssid': fields.get("ssid", entdefs["Collab"]["ssid"]["dv"])}
    cursor.execute(stmt, data)
    fields["dsId"] = cursor.lastrowid
    cnx.commit()
    fields = db2app_Collab(fields)
    dblogmsg("ADD", "Collab", fields)
    return fields


# Update the specified Collab row with the given field values.
def update_existing_Collab(context, fields):
    fields = app2db_Collab(fields, fill=False)
    dsId = int(fields["dsId"])  # Verify int value
    stmt = ""
    for field in fields:  # only updating the fields passed in
        if stmt:
            stmt += ", "
        stmt += field + "=(%(" + field + ")s)"
    stmt = "UPDATE Collab SET " + stmt + " WHERE dsId=" + str(dsId)
    if context["vck"] != "override":
        stmt += " AND modified=\"" + context["vck"] + "\""
    data = {}
    for field in fields:
        data[field] = fields[field]
    context["cursor"].execute(stmt, data)
    if context["cursor"].rowcount < 1 and context["vck"] != "override":
        logging.error(stmt + " " + json.dumps(data))
        entcache.cache_clean()  # out of sync, clear it all
        raise ValueError("Collab" + str(dsId) + " update received outdated version check value " + context["vck"] + ".")
    context["cnx"].commit()
    result = context["existing"]
    for field in fields:
        result[field] = fields[field]
    result = db2app_Collab(result)
    dblogmsg("UPD", "Collab", result)
    entcache.cache_remove(result)
    return result


# Write a new SKeyMap row, using the given field values or defaults.
def insert_new_SKeyMap(cnx, cursor, fields):
    fields = app2db_SKeyMap(fields)
    stmt = (
        "INSERT INTO SKeyMap (created, modified, skey, spid, notes) "
        "VALUES (%(created)s, %(modified)s, %(skey)s, %(spid)s, %(notes)s)")
    data = {
        'created': fields.get("created"),
        'modified': fields.get("modified"),
        'skey': fields.get("skey", entdefs["SKeyMap"]["skey"]["dv"]),
        'spid': fields.get("spid", entdefs["SKeyMap"]["spid"]["dv"]),
        'notes': fields.get("notes", entdefs["SKeyMap"]["notes"]["dv"])}
    cursor.execute(stmt, data)
    fields["dsId"] = cursor.lastrowid
    cnx.commit()
    fields = db2app_SKeyMap(fields)
    dblogmsg("ADD", "SKeyMap", fields)
    return fields


# Update the specified SKeyMap row with the given field values.
def update_existing_SKeyMap(context, fields):
    fields = app2db_SKeyMap(fields, fill=False)
    dsId = int(fields["dsId"])  # Verify int value
    stmt = ""
    for field in fields:  # only updating the fields passed in
        if stmt:
            stmt += ", "
        stmt += field + "=(%(" + field + ")s)"
    stmt = "UPDATE SKeyMap SET " + stmt + " WHERE dsId=" + str(dsId)
    if context["vck"] != "override":
        stmt += " AND modified=\"" + context["vck"] + "\""
    data = {}
    for field in fields:
        data[field] = fields[field]
    context["cursor"].execute(stmt, data)
    if context["cursor"].rowcount < 1 and context["vck"] != "override":
        logging.error(stmt + " " + json.dumps(data))
        entcache.cache_clean()  # out of sync, clear it all
        raise ValueError("SKeyMap" + str(dsId) + " update received outdated version check value " + context["vck"] + ".")
    context["cnx"].commit()
    result = context["existing"]
    for field in fields:
        result[field] = fields[field]
    result = db2app_SKeyMap(result)
    dblogmsg("UPD", "SKeyMap", result)
    entcache.cache_remove(result)
    return result


# Write a new AppService row, using the given field values or defaults.
def insert_new_AppService(cnx, cursor, fields):
    fields = app2db_AppService(fields)
    stmt = (
        "INSERT INTO AppService (created, modified, name, ckey, csec, data) "
        "VALUES (%(created)s, %(modified)s, %(name)s, %(ckey)s, %(csec)s, %(data)s)")
    data = {
        'created': fields.get("created"),
        'modified': fields.get("modified"),
        'name': fields.get("name", entdefs["AppService"]["name"]["dv"]),
        'ckey': fields.get("ckey", entdefs["AppService"]["ckey"]["dv"]),
        'csec': fields.get("csec", entdefs["AppService"]["csec"]["dv"]),
        'data': fields.get("data", entdefs["AppService"]["data"]["dv"])}
    cursor.execute(stmt, data)
    fields["dsId"] = cursor.lastrowid
    cnx.commit()
    fields = db2app_AppService(fields)
    dblogmsg("ADD", "AppService", fields)
    return fields


# Update the specified AppService row with the given field values.
def update_existing_AppService(context, fields):
    fields = app2db_AppService(fields, fill=False)
    dsId = int(fields["dsId"])  # Verify int value
    stmt = ""
    for field in fields:  # only updating the fields passed in
        if stmt:
            stmt += ", "
        stmt += field + "=(%(" + field + ")s)"
    stmt = "UPDATE AppService SET " + stmt + " WHERE dsId=" + str(dsId)
    if context["vck"] != "override":
        stmt += " AND modified=\"" + context["vck"] + "\""
    data = {}
    for field in fields:
        data[field] = fields[field]
    context["cursor"].execute(stmt, data)
    if context["cursor"].rowcount < 1 and context["vck"] != "override":
        logging.error(stmt + " " + json.dumps(data))
        entcache.cache_clean()  # out of sync, clear it all
        raise ValueError("AppService" + str(dsId) + " update received outdated version check value " + context["vck"] + ".")
    context["cnx"].commit()
    result = context["existing"]
    for field in fields:
        result[field] = fields[field]
    result = db2app_AppService(result)
    dblogmsg("UPD", "AppService", result)
    entcache.cache_put(result)
    return result


# Write the given dict/object based on the dsType.  Binary field values must
# be base64.b64encode.  Unspecified fields are set to default values for a
# new instance, and left alone on update.  For update, the verification
# check value must match the modified value of the existing instance.
def write_entity(inst, vck="1234-12-12T00:00:00Z"):
    cnx = get_mysql_connector()
    if not cnx:
        raise ValueError("Database connection failed.")
    try:
        cursor = cnx.cursor()
        try:
            entity = inst.get("dsType", None)
            dsId = inst.get("dsId", 0)
            if dsId:
                existing = verify_timestamp_fields(entity, dsId, inst, vck)
                context = {"cnx":cnx, "cursor":cursor, "vck":vck,
                           "existing":existing}
                if entity == "DigAcc":
                    return update_existing_DigAcc(context, inst)
                if entity == "Song":
                    return update_existing_Song(context, inst)
                if entity == "Collab":
                    return update_existing_Collab(context, inst)
                if entity == "SKeyMap":
                    return update_existing_SKeyMap(context, inst)
                if entity == "AppService":
                    return update_existing_AppService(context, inst)
                raise ValueError("Cannot modify unknown entity dsType " +
                                 str(entity))
            # No existing instance to update.  Insert new.
            initialize_timestamp_fields(inst, vck)
            if entity == "DigAcc":
                return insert_new_DigAcc(cnx, cursor, inst)
            if entity == "Song":
                return insert_new_Song(cnx, cursor, inst)
            if entity == "Collab":
                return insert_new_Collab(cnx, cursor, inst)
            if entity == "SKeyMap":
                return insert_new_SKeyMap(cnx, cursor, inst)
            if entity == "AppService":
                return insert_new_AppService(cnx, cursor, inst)
            raise ValueError("Cannot create unknown entity dsType " +
                             str(entity))
        except mysql.connector.Error as e:
            raise ValueError(str(e) or "No mysql error text")  # see note 1
        finally:
            cursor.close()
    finally:
        cnx.close()


def delete_entity(entity, dsId):
    cnx = get_mysql_connector()
    if not cnx:
        raise ValueError("Database connection failed.")
    try:
        cursor = cnx.cursor()
        try:
            stmt = "DELETE FROM " + entity + " WHERE dsId=" + str(dsId)
            cursor.execute(stmt)
            cnx.commit()
            dblogmsg("DEL", entity + " " + str(dsId), None)
            # if cache cleanup is needed that is up to caller
        except mysql.connector.Error as e:
            raise ValueError(str(e) or "No mysql error text")  # see note 1
        finally:
            cursor.close()
    finally:
        cnx.close()


def query_DigAcc(cnx, cursor, where):
    query = "SELECT dsId, created, modified, "
    query += "email, phash, hubdat, status, actsends, actcode, firstname, hashtag, kwdefs, igfolds, settings, musfs"
    query += " FROM DigAcc " + where
    cursor.execute(query)
    res = []
    for (dsId, created, modified, email, phash, hubdat, status, actsends, actcode, firstname, hashtag, kwdefs, igfolds, settings, musfs) in cursor:
        inst = {"dsType": "DigAcc", "dsId": dsId, "created": created, "modified": modified, "email": email, "phash": phash, "hubdat": hubdat, "status": status, "actsends": actsends, "actcode": actcode, "firstname": firstname, "hashtag": hashtag, "kwdefs": kwdefs, "igfolds": igfolds, "settings": settings, "musfs": musfs}
        inst = db2app_DigAcc(inst)
        res.append(inst)
    dblogmsg("QRY", "DigAcc", res)
    return res


def query_Song(cnx, cursor, where):
    query = "SELECT dsId, created, modified, "
    query += "aid, path, ti, ar, ab, smti, smar, smab, el, al, kws, rv, fq, lp, nt, pc, srcid, srcrat, spid"
    query += " FROM Song " + where
    cursor.execute(query)
    res = []
    for (dsId, created, modified, aid, path, ti, ar, ab, smti, smar, smab, el, al, kws, rv, fq, lp, nt, pc, srcid, srcrat, spid) in cursor:
        inst = {"dsType": "Song", "dsId": dsId, "created": created, "modified": modified, "aid": aid, "path": path, "ti": ti, "ar": ar, "ab": ab, "smti": smti, "smar": smar, "smab": smab, "el": el, "al": al, "kws": kws, "rv": rv, "fq": fq, "lp": lp, "nt": nt, "pc": pc, "srcid": srcid, "srcrat": srcrat, "spid": spid}
        inst = db2app_Song(inst)
        res.append(inst)
    dblogmsg("QRY", "Song", res)
    return res


def query_Collab(cnx, cursor, where):
    query = "SELECT dsId, created, modified, "
    query += "ctype, rec, src, ssid"
    query += " FROM Collab " + where
    cursor.execute(query)
    res = []
    for (dsId, created, modified, ctype, rec, src, ssid) in cursor:
        inst = {"dsType": "Collab", "dsId": dsId, "created": created, "modified": modified, "ctype": ctype, "rec": rec, "src": src, "ssid": ssid}
        inst = db2app_Collab(inst)
        res.append(inst)
    dblogmsg("QRY", "Collab", res)
    return res


def query_SKeyMap(cnx, cursor, where):
    query = "SELECT dsId, created, modified, "
    query += "skey, spid, notes"
    query += " FROM SKeyMap " + where
    cursor.execute(query)
    res = []
    for (dsId, created, modified, skey, spid, notes) in cursor:
        inst = {"dsType": "SKeyMap", "dsId": dsId, "created": created, "modified": modified, "skey": skey, "spid": spid, "notes": notes}
        inst = db2app_SKeyMap(inst)
        res.append(inst)
    dblogmsg("QRY", "SKeyMap", res)
    return res


def query_AppService(cnx, cursor, where):
    query = "SELECT dsId, created, modified, "
    query += "name, ckey, csec, data"
    query += " FROM AppService " + where
    cursor.execute(query)
    res = []
    for (dsId, created, modified, name, ckey, csec, data) in cursor:
        inst = {"dsType": "AppService", "dsId": dsId, "created": created, "modified": modified, "name": name, "ckey": ckey, "csec": csec, "data": data}
        inst = db2app_AppService(inst)
        res.append(inst)
    dblogmsg("QRY", "AppService", res)
    return res


# Fetch all instances of the specified entity kind for the given WHERE
# clause.  The WHERE clause should include a LIMIT, and should only match on
# indexed fields and/or declared query indexes.  For speed and general
# compatibility, only one inequality operator should be used in the match.
def query_entity(entity, where):
    cnx = get_mysql_connector()
    if not cnx:
        raise ValueError("Database connection failed.")
    try:
        cursor = cnx.cursor()
        try:
            if entity == "DigAcc":
                return query_DigAcc(cnx, cursor, where)
            if entity == "Song":
                return query_Song(cnx, cursor, where)
            if entity == "Collab":
                return query_Collab(cnx, cursor, where)
            if entity == "SKeyMap":
                return query_SKeyMap(cnx, cursor, where)
            if entity == "AppService":
                return query_AppService(cnx, cursor, where)
        except mysql.connector.Error as e:
            raise ValueError(str(e) or "No mysql error text")  # see note 1
        finally:
            cursor.close()
    finally:
        cnx.close()


def visible_DigAcc_fields(obj, audience):
    filtobj = {}
    for fld, val in obj.items():
        if fld == "email" and audience != "private":
            continue
        if fld == "phash":
            continue
        if fld == "hubdat" and audience != "private":
            continue
        if fld == "status" and audience != "private":
            continue
        if fld == "actsends":
            continue
        if fld == "actcode":
            continue
        filtobj[fld] = val
    return filtobj


def visible_Song_fields(obj, audience):
    filtobj = {}
    for fld, val in obj.items():
        filtobj[fld] = val
    return filtobj


def visible_Collab_fields(obj, audience):
    filtobj = {}
    for fld, val in obj.items():
        filtobj[fld] = val
    return filtobj


def visible_SKeyMap_fields(obj, audience):
    filtobj = {}
    for fld, val in obj.items():
        filtobj[fld] = val
    return filtobj


def visible_AppService_fields(obj, audience):
    filtobj = {}
    for fld, val in obj.items():
        filtobj[fld] = val
    return filtobj


# Return a copied object with only the fields appropriate to the audience.
# Specifying audience="private" includes peronal info.  The given obj is
# assumed to already have been through db2app conversion.  Image fields are
# converted to dsId values for separate download.
def visible_fields(obj, audience="public"):
    if obj["dsType"] == "DigAcc":
        return visible_DigAcc_fields(obj, audience)
    if obj["dsType"] == "Song":
        return visible_Song_fields(obj, audience)
    if obj["dsType"] == "Collab":
        return visible_Collab_fields(obj, audience)
    if obj["dsType"] == "SKeyMap":
        return visible_SKeyMap_fields(obj, audience)
    if obj["dsType"] == "AppService":
        return visible_AppService_fields(obj, audience)
    raise ValueError("Unknown object dsType: " + obj["dsType"])


# Make a unique key from the ti/ar/ab song fields
def get_song_key(song):
    ti = song["ti"]
    ar = song.get("ar", "")
    ab = song.get("ab", "")
    srx = re.compile(r"[s'\"]")
    skey = re.sub(srx, "", ti) + re.sub(srx, "", ar) + re.sub(srx, "", ab)
    skey = skey.lower()
    return skey


# For a given user, count their total songs and how many are streaming
def fetch_song_counts(uid):
    cnx = get_mysql_connector()
    if not cnx:
        raise ValueError("Database connection failed.")
    try:
        cursor = cnx.cursor()
        try:
            query = ("SELECT COUNT(dsId) AS hubdb" +
                     ", COUNT(IF(spid LIKE \"z:%\", 1, NULL)) AS spotify" +
                     " FROM (SELECT dsId, spid FROM Song WHERE aid=" +
                     str(uid) + " AS usersongs;")
            cursor.execute(query)
            res = []
            for (hubdb, spotify) in cursor:
                res.append({"hubdb":hubdb, "spotify":spotify})
            return res
        except mysql.connector.Error as e:
            raise ValueError(str(e) or "No song fetch error details")
        finally:
            cursor.close()
    finally:
        cnx.close()


def collaborate_default_ratings(uid, fid, since="1970-01-01T00:00:00Z",
                                limit=200):
    cnx = get_mysql_connector()
    if not cnx:
        raise ValueError("Database connection failed.")
    try:
        cursor = cnx.cursor()
        try:
            query = ("SELECT us.dsId as dsId" +
                     ", us.created as created, us.modified as modified" +
                     ", us.ti as ti, us.ar as ar, us.ab as ab" +
                     ", fs.aid as mfid, fs.created as mfcreated" +
                     ", fs.el as el, fs.al as al, fs.kws as kws, fs.rv as rv" +
                     " FROM Song AS us, Song AS fs" +
                     " WHERE us.aid=" + uid + " AND fs.aid=" + fid +
                     " AND fs.created > \"" + since + "\""
                     " AND us.smti=fs.smti AND us.smar=fs.smar" +
                     " AND us.el = 49 AND us.al = 49 AND us.kws IS NULL" +
                     " AND (fs.el != 49 OR fs.al != 49 OR fs.kws IS NOT NULL)" +
                     " ORDER BY fs.created LIMIT " + str(limit))
            logging.info("collab query: " + query)
            cursor.execute(query)
            res = []
            for (dsId, created, modified, ti, ar, ab, mfid, mfcreated,
                 el, al, kws, rv) in cursor:
                res.append({"dsType":"Song", "dsId":str(dsId),
                            "created":created, "modified":modified,
                            "ti":ti, "ar":ar, "ab":ab,
                            "mfid":str(mfid), "mfcreated":mfcreated,
                            "el":el, "al":al, "kws":kws, "rv":rv})
            logging.info("collab res " + str(len(res)) + " Songs")
            return res
        except mysql.connector.Error as e:
            raise ValueError(str(e) or "No collab error details")
        finally:
            cursor.close()
    finally:
        cnx.close()


# Count the songs for the given user from the given music friend
def count_contributions(uid, mfid):
    cnx = get_mysql_connector()
    if not cnx:
        raise ValueError("Database connection failed.")
    try:
        cursor = cnx.cursor()
        try:
            query = ("SELECT COUNT(dsId) AS ccnt" +
                     " FROM Song WHERE aid=" + str(uid) +
                     " AND srcid=" + str(mfid))
            cursor.execute(query)
            res = []
            for ccnt in cursor:
                res.append({"mfid":mfid, "ccnt":ccnt})
            return res
        except mysql.connector.Error as e:
            raise ValueError(str(e) or "No song fetch error details")
        finally:
            cursor.close()
    finally:
        cnx.close()


def initial_keywords():
    #  DO NOT EDIT. Change defs in makeCRUD.js
    return {
        "Social": {"pos": 1, "sc": 0, "ig": 0, "dsc": "Music I might select to play when other people are listening."},
        "Personal": {"pos": 2, "sc": 0, "ig": 0, "dsc": "Music I might select to play when it's just me listening."},
        "Office": {"pos": 3, "sc": 0, "ig": 0, "dsc": "Music that you can listen to while you work."},
        "Dance": {"pos": 4, "sc": 0, "ig": 0, "dsc": "Music you would dance to."},
        "Ambient": {"pos": 0, "sc": 0, "ig": 0, "dsc": "Music that can be listened to from zero to full attention, transitioning from and to silence."},
        "Jazz": {"pos": 0, "sc": 0, "ig": 0, "dsc": "However you define it for your collection."},
        "Classical": {"pos": 0, "sc": 0, "ig": 0, "dsc": "However you define it for your collection."},
        "Talk": {"pos": 0, "sc": 0, "ig": 0, "dsc": "Spoken word."},
        "Solstice": {"pos": 0, "sc": 0, "ig": 0, "dsc": "Holiday seasonal."}}


